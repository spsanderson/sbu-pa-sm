---
title: "Sample Time Series"
author: "Steven P. Sanderson II, MPH"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: tango
    theme: flatly
    toc: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
    echo = TRUE,
    message = F,
    warning = F,
    paged.print = FALSE,
    out.width = "100%",
    out.height = "100%"
)
```

```{r run_main_script, include=FALSE, echo=FALSE, warning=FALSE}
source("00_Scripts/main.R")
```

# Purpose

The purpose of this document is to illustrate time series analysis and forecasting. We will use a simulated dataset to analyze things like visits, discharges and payments. To perform these analyses we will be following the `modeltime` workflow. This report will be broken down into sections that follow that same workflow.

# Data View

Lets take a look at our data and see what it has.

```{r data_view}
df_tbl %>%
  glimpse()
```

```{r skimr}
skim(df_tbl)
```

# Preparing Data

Our objectives are to:

- Aggregate data to common time-stamps
- Apply any transformations
- Detect any lags & add rolling features
- Create a Full Data Set: Adding Future observations, lags, and external regressors

Our forecasting will focus on a grouped forecast where we are going to forecast the number of discharges by inpatient/outpatient visit type and by payer grouping.

We are going to do this on a weekly scale.

## Aggregate discharges by IP/OP and Payer Grouping by Week

1. Start with `df_tbl`
2. Use `summarise_by_time()` with `.by = "week"`, and `n()` the visits.
3. Save as a new variable called `transactions_weekly_tbl`

```{r transactions_weekly_tbl}
transactions_weekly_tbl <- df_tbl %>%
  filter(payer_grouping != "?") %>%
  group_by(ip_op_flag, payer_grouping) %>%
  summarise_by_time(
    .date_var = dsch_date
    , .by     = "week"
    , value   = n()
  )

transactions_weekly_tbl
```

# Visualizations

## Visualize Discharges

Use `plot_time_series()` to visualize the discharges. 

- Look for outliers & any data issues
- Try out a `log()` transformation to see the effect on the time series

```{r weekly_ts}
transactions_weekly_tbl %>%
  plot_time_series(
    .date_var     = dsch_date
    , .color_var  = payer_grouping
    , .facet_vars = payer_grouping
    , .facet_ncol = 2
    , .value      = log(value)
    , .smooth     = FALSE
  )
```

## Visualize ACF

Visualize the ACF using `plot_acf_diagnostics()` using a `log()` transformation. Look for:

- Any frequencies we can include?
- Any lags we can include? (Hint - What is our forecast horizon?)

```{r}
transactions_weekly_tbl %>%
  ungroup() %>%
  plot_acf_diagnostics(dsch_date, log(value))
```

## Log-Standardize Revenue (Target)

- Start with `transactions_weekly_tbl`
- Apply log-standardization:
    - Apply Log transformation using `log()`
    - Apply standardization to mean = 0, sd = 1 using `standardize_vec()`
- Store the resulting data as `transactions_trans_weekly_tbl`

```{r, message = TRUE}
transactions_trans_weekly_tbl <- transactions_weekly_tbl %>%
  mutate(value = log(value)) %>%
  mutate(value = standardize_vec(value))

mean_a <- 3.08875144281386
sd_a   <- 0.367674566335952
mean_b <- 1.83577890003612
sd_b   <- 0.545791389303644
mean_c <- 3.15330156564258
sd_c   <- 0.302421031976675
mean_d <- 1.59951348649452
sd_d   <- 0.514947645076106
```

Visualize the log-standardized transactions using `plot_time_series()`. This confirms the transformation was performed successfully. 

```{r}
transactions_trans_weekly_tbl %>%
      plot_time_series(
    .date_var     = dsch_date
    , .color_var  = payer_grouping
    , .facet_vars = payer_grouping
    , .facet_ncol = 2
    , .value      = value
    , .smooth     = FALSE
  )
```

We'll use these parameters to create our "full dataset". We've selected an 14-week forecast horizon. Our lag period is 14 weeks and we'll try out a few rolling averages at various aggregations. 

```{r}
horizon         <- 14
lag_period      <- 14
rolling_periods <- c(7, 14, 28, 52)
```

## Prepare the full data

1. Start with `transactions_weekly_tbl`
2. __Add the future window:__ Use `bind_rows()` and `future_frame()` to extend the data frame `.length_out = horizon`.
3. __Add autocorrelated lags:__ Use `tk_augment_lags()` to add a `.lags = lag_period`
4. __Add rolling features from our lag__: Use `tk_agument_slidify()` to add `.period = rolling_periods`. Use `mean` as the rolling function. Make sure to "center" with "partial" windows. 
5. Rename any columns that contain "lag". Modify to start with "lag_"
6. Save the output as `full_tbl`.


```{r}
full_tbl <- transactions_trans_weekly_tbl %>%
    
    # Add future window
    bind_rows(
        future_frame(
          .data         = .
          , .date_var   = dsch_date
          , .length_out = horizon
        )
    ) %>%
    
    # Add autocorrelated lags
    tk_augment_lags(value, .lags = lag_period) %>%
    
    # Add rolling features
    tk_augment_slidify(
        .value   = value_lag14,
        .f       = mean, 
        .period  = rolling_periods,
        .align   = "center",
        .partial = TRUE
    ) %>%
    
    # Rename columns
    rename_with(
      .cols = contains("lag")
      , .fn = ~ str_c("lag_", .)
    ) %>%
  select(dsch_date, everything())

full_tbl %>% 
  glimpse()
```

## Visualize the Full Data

Visualize the features, and review what you see. 

1. Start with `full_tbl`
2. `pivot_longer` every column except "dsch_date"
3. Use `plot_time_series()` to visualize the time series coloring by "name". 

Review the visualization selecting one feature at a time and answering the following questions:
    
    - Do the rolling lags present any issues? 
    - Which rolling lag captures the trend the best?
    - Do you expect either of the Product Events features to help?

```{r}
full_tbl %>%
  pivot_longer(cols = -c(dsch_date, lag_ip_op_flag, payer_grouping)) %>%
  plot_time_series(
    dsch_date
    , value
    , name
    , .smooth = FALSE
    , .facet_ncol = 2
  )
```

# Model Data / Forecast Data Split

Create a `data_prepared_tbl` by filtering `full_tbl` where "value" is non-missing. 

```{r}
data_prepared_tbl <- full_tbl %>%
    filter(!is.na(value))
data_prepared_tbl
```

Create a `forecast_tbl` by filtering `full_tbl` where "value" is missing. 

```{r}
forecast_tbl <- full_tbl %>%
    filter(is.na(value))
forecast_tbl
```

# Train / Test Split

## Split into Train / Test Sets

- Start with `data_prepared_tbl`
- Use `time_series_split()` to create a single time series split. 
    - Set `assess = horizon` to get the last 14-weeks of data as testing data. 
    - Set `cumulative = TRUE` to use all of the previous data as training data. 
- Save the object as `splits`

```{r}
splits <- data_prepared_tbl %>% 
    time_series_split(assess = horizon, cumulative = TRUE)
```

# Feature Engineering

## Create a Preprocessing recipe

Make a preprocessing recipe using `recipe()`. Note - It may help to `prep()` and `juice()` your recipe to see the effect of your transformations. 

- Start with `recipe()` using "value ~ ." and `data = training(splits)`
- Add the following steps:
    - `step_timeseries_signature()` using the date feature
    - Remove any newly created features that:
        - Contain ".iso"
        - End with "xts"
        - Contain "day", "hour", "minute", "second" or "am.pm" (because this is a weekly dataset and these features won't add any predictive value)
    - Normalize all numeric data except for "value" (the target) with `step_normalize()`.
    - Dummy all categorical features with `step_dummy()`. Set `one_hot = TRUE`.
    - Add a fourier series at periods 7 and 14. Set K = 2 for both. 

```{r}
recipe_spec_base <- recipe(
  value ~ .
  , data = training(splits) %>%
    arrange(
      lag_ip_op_flag
      , payer_grouping
      , dsch_date)
  ) %>%
    
    # Time Series Signature
    step_timeseries_signature(dsch_date) %>%
    step_rm(matches("(iso)|(xts)|(hour)|(minute)|(second)|(am.pm)")) %>%
    
    # Standardization
    step_normalize(matches("(index.num)|(year)|(yday)")) %>%
    
    # Dummy Encoding (One Hot Encoding)
    step_dummy(all_nominal(), one_hot = TRUE) %>%
    
    # Fourier - 4 Week ACF
    step_fourier(dsch_date, period = c(7, 14, 52), K = 2)

recipe_spec_base %>% 
  prep() %>% 
  juice() %>% 
  glimpse()
```

# Modeling

## Spline Model

### Visualize

Use `plot_time_series_regression` to test out several natural splines:

- Use .formula to try out `splines::ns()` with degrees of freedom 1, 2, 3, and 4. 

Which value of `df` would you select?

```{r}
data_prepared_tbl %>%
    plot_time_series_regression(
        .date_var     = dsch_date,
        .formula      = value ~ splines::ns(dsch_date, df = 3),
        .show_summary = FALSE,
        .facet_ncol   = 2
    )
```